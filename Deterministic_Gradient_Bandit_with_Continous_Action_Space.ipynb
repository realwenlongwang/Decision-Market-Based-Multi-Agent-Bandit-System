{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Bandits Agent with Policy Gradient Method (Deterministic) in Prediction Markets Problem\n",
    "---\n",
    "This is a program that simulates an agent who trades in a prediction market. The problem that the prediction market aims to solve is to predict the real distribution of a random variable. We define the random variable as the colour of a bucket. The problem design comes from a human-subjective experiment for decision markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "from tqdm.notebook import tnrange\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logit, expit\n",
    "from PolicyGradientAgent import DeterministicGradientAgent\n",
    "from Environment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c036051707534933aa4db6402967f0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating weights with regular algorithm.\n"
     ]
    }
   ],
   "source": [
    "learning_rate_theta = 0.0005\n",
    "decay_rate = 0 #0.001\n",
    "learning_rate_wq = 0.0003\n",
    "memory_size = 256\n",
    "batch_size = 256\n",
    "training_episodes = 6000 * 5 *2\n",
    "beta1 = 0.9\n",
    "beta2 = 0.9999\n",
    "# Algorithm: adam, momentum, regular\n",
    "algorithm = 'regular'\n",
    "# Bucket parameters\n",
    "prior_red = 0.5\n",
    "pr_red_ball_red_bucket = 2/3\n",
    "pr_red_ball_blue_bucket = 1/3\n",
    "\n",
    "agent = DeterministicGradientAgent(feature_shape=[1, 3], learning_rate_theta=learning_rate_theta, learning_rate_wq=learning_rate_wq, memory_size= memory_size, batch_size=batch_size ,beta1=beta1, beta2=beta2)\n",
    "\n",
    "explorer = Explorer(feature_shape=[1, 3], learning= False, init_learning_rate=0.003)\n",
    "\n",
    "qv_history = []\n",
    "\n",
    "reward_history_list = []\n",
    "regret_history_list = []\n",
    "average_reward = 0\n",
    "actual_average_reward = 0\n",
    "\n",
    "mean_weights_history_list = []\n",
    "\n",
    "r_ball_mean_history_list = []\n",
    "b_ball_mean_history_list = []\n",
    "\n",
    "\n",
    "r_ball_pred_history_list = []\n",
    "b_ball_pred_history_list = []\n",
    "\n",
    "grad_r_ball_mean_history_list = []\n",
    "grad_b_ball_mean_history_list = []\n",
    "\n",
    "\n",
    "grad_r_ball_v_mean_history_list = []\n",
    "grad_b_ball_v_mean_history_list = []\n",
    "\n",
    "\n",
    "grad_r_ball_adam_mean_history_list = []\n",
    "grad_b_ball_adam_mean_history_list = []\n",
    "\n",
    "explorer_std_list = []\n",
    "\n",
    "grad_mean_history_list = []\n",
    "mean_history_list = []\n",
    "actual_report_history_list = []\n",
    "\n",
    "\n",
    "for t in tnrange(training_episodes):\n",
    "    # Prepare a bucket and a prediction market\n",
    "    bucket = Bucket(prior_red, pr_red_ball_red_bucket, pr_red_ball_blue_bucket)\n",
    "    pm = PredictionMarket(outcomes_list=['red_bucket', 'blue_bucket'])\n",
    "    signal = bucket.signal()\n",
    "    x = one_hot_encode(signal)\n",
    "    x.append(prior_red)\n",
    "\n",
    "    mean = agent.report(x)\n",
    "    pi = expit(mean)\n",
    "    actual_report = [pi, 1-pi]\n",
    "    explorer.set_parameters(mean=mean)\n",
    "    noised_report = explorer.report(x)\n",
    "    \n",
    "    explorer_std_list.append(explorer.std)\n",
    "\n",
    "    pm.report(noised_report)\n",
    "    R = pm.log_resolve(bucket_colour_to_num[bucket.colour])\n",
    "    \n",
    "    pm.report(actual_report)\n",
    "    actual_R = pm.log_resolve(bucket_colour_to_num[bucket.colour])\n",
    "\n",
    "\n",
    "    average_reward = average_reward + (1/ (t + 1)) * (R - average_reward)\n",
    "    actual_average_reward = actual_average_reward + (1/ (t + 1)) * (actual_R - actual_average_reward)\n",
    "    reward_history_list.append([R, average_reward, actual_R, actual_average_reward])\n",
    "    mean_weights_history_list.append(agent.theta_mean[0].tolist())   \n",
    "\n",
    "    R_perf = 0\n",
    "    red_score = np.log(actual_report[0]) - np.log(0.5)\n",
    "    blue_score = np.log(actual_report[1]) - np.log(0.5)\n",
    "    red_expectation = pr_red_ball_red_bucket  * red_score + (1 - pr_red_ball_red_bucket)  * blue_score\n",
    "    blue_expectation = pr_red_ball_blue_bucket  * red_score + (1 - pr_red_ball_blue_bucket)  * blue_score\n",
    "    red_max_expectation = pr_red_ball_red_bucket * (np.log(pr_red_ball_red_bucket) - np.log(0.5)) + (1 - pr_red_ball_red_bucket) * (np.log(1 - pr_red_ball_red_bucket) - np.log(0.5))\n",
    "    blue_max_expectation = pr_red_ball_blue_bucket * (np.log(pr_red_ball_blue_bucket) - np.log(0.5)) + (1 - pr_red_ball_blue_bucket) * (np.log(1 - pr_red_ball_blue_bucket) - np.log(0.5))\n",
    "    if signal == 'red':\n",
    "        R_perf = red_expectation\n",
    "        regret = red_max_expectation - red_expectation\n",
    "    else:\n",
    "        R_perf = blue_expectation\n",
    "        regret = blue_max_expectation - blue_expectation\n",
    "    regret_history_list.append(regret)\n",
    "    \n",
    "    \n",
    "    action = logit(noised_report[0])\n",
    "    agent.store_experience(x, action, R, t)\n",
    "\n",
    "    explorer.update(R, x)\n",
    "\n",
    "    try:\n",
    "        grad_mean, v_dw_mean_corrected, s_dw_mean_corrected, q, v = agent.batch_update(t, algorithm= algorithm)\n",
    "    except AssertionError:\n",
    "        tb = traceback.format_exc()\n",
    "        print(tb)\n",
    "\n",
    "    agent.learning_rate_decay(epoch=t, decay_rate=decay_rate)\n",
    "    if explorer.learning:\n",
    "        explorer.learning_rate_decay(epoch=t, decay_rate=decay_rate)\n",
    "    qv_history.append([v, q])\n",
    "        \n",
    "    if signal == 'red':\n",
    "        r_ball_pred_history_list.append(noised_report[0])\n",
    "        r_ball_mean_history_list.append(mean)      \n",
    "    else:\n",
    "        b_ball_pred_history_list.append(noised_report[0])\n",
    "        b_ball_mean_history_list.append(mean)\n",
    "        \n",
    "    actual_report_history_list.append([actual_report[0], signal])\n",
    "    mean_history_list.append([mean, signal])\n",
    "    grad_mean_history_list.append(grad_mean[0, :])    \n",
    "\n",
    "        \n",
    "    grad_r_ball_mean_history_list.append(grad_mean[0, 0])\n",
    "    ##########\n",
    "    grad_r_ball_v_mean_history_list.append(v_dw_mean_corrected[0, 0])\n",
    "    grad_r_ball_adam_mean_history_list.append(s_dw_mean_corrected[0, 0])\n",
    "    \n",
    "    grad_b_ball_mean_history_list.append(grad_mean[0, 1])\n",
    "    #########\n",
    "    grad_b_ball_v_mean_history_list.append(v_dw_mean_corrected[0, 1])\n",
    "    grad_b_ball_adam_mean_history_list.append(s_dw_mean_corrected[0, 1])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qv_array = np.array(qv_history)\n",
    "\n",
    "reward_history = np.array(reward_history_list)\n",
    "regret_history = np.array(regret_history_list)\n",
    "\n",
    "mean_weights_history = np.array(mean_weights_history_list)\n",
    "\n",
    "\n",
    "grad_r_ball_mean_history = np.array(grad_r_ball_mean_history_list)\n",
    "grad_b_ball_mean_history = np.array(grad_b_ball_mean_history_list)\n",
    "\n",
    "\n",
    "grad_r_ball_v_mean_history = np.array(grad_r_ball_v_mean_history_list)\n",
    "grad_b_ball_v_mean_history = np.array(grad_b_ball_v_mean_history_list)\n",
    "\n",
    "\n",
    "grad_r_ball_adam_mean_history = np.array(grad_r_ball_adam_mean_history_list)\n",
    "grad_b_ball_adam_mean_history = np.array(grad_b_ball_adam_mean_history_list)\n",
    "\n",
    "grad_mean_history_df = pd.DataFrame(grad_mean_history_list, columns=['red_ball', 'blue_ball', 'prior'])\n",
    "actual_report_history_df = pd.DataFrame(actual_report_history_list, columns=['report', 'signal'])\n",
    "mean_history_df = pd.DataFrame(mean_history_list, columns=['mean', 'signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agent.theta_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_best = 2/3*(np.log(2/3)-np.log(1/2)) + 1/3*(np.log(1/3)-np.log(1/2))\n",
    "empirical_best = np.mean(reward_history[-100:, 3])\n",
    "print('Towards best ratio: ', empirical_best/ theoretical_best)\n",
    "fig, axs = plt.subplots(3, figsize=(15, 8))\n",
    "axs[0].plot(reward_history[:, 0], 'b.',label = 'Noised log rewards', zorder=-100)\n",
    "axs[0].plot(reward_history[:, 2], 'r.',label = 'Actual log rewards', zorder=-99, alpha=0.8)\n",
    "axs[1].plot(not_outlier(reward_history[:, 1]),zorder= -100, label = 'Noised average reward')\n",
    "axs[1].plot(not_outlier(reward_history[:, 3]),zorder= -99, label = 'Actual average reward')\n",
    "axs[2].plot(not_outlier(regret_history), 'g.',label='Regret')\n",
    "axs[0].hlines(y=np.log(2), xmin=0, xmax=reward_history.shape[0], colors='black', linestyles='dashdot')\n",
    "axs[0].hlines(y=0.0, xmin=0, xmax=reward_history.shape[0] , colors='black', linestyles='dashdot')\n",
    "axs[1].hlines(y=0.0, xmin=0, xmax=reward_history.shape[0] , colors='black', linestyles='dashdot')\n",
    "axs[1].hlines(y=theoretical_best, xmin=0, xmax=reward_history.shape[0] , colors='black', linestyles='dashdot')\n",
    "fig.legend()\n",
    "fig.suptitle('Actual Rewards and Average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 4))\n",
    "plt.plot(qv_array[:, 0], zorder = -99, label = 'V_approx', alpha=0.8)\n",
    "plt.plot(qv_array[:, 1], zorder= -100, label = 'Q_approx')\n",
    "[ax] = fig.axes\n",
    "ax.tick_params(labelright=True)\n",
    "plt.plot(not_outlier(reward_history[:, 1]), 'r', zorder= -101, label = 'Noised average reward' )\n",
    "plt.hlines(y=theoretical_best, xmin=0, xmax=reward_history.shape[0] , colors='black', linestyles='dashdot')\n",
    "# plt.hlines(y=np.log(2), xmin=0, xmax=reward_history.shape[0], colors='black', linestyles='dashdot')\n",
    "# plt.hlines(y=0.0, xmin=0, xmax=reward_history.shape[0] , colors='black', linestyles='dashdot')\n",
    "plt.legend()\n",
    "plt.title('Approximated value and Actual value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 4))\n",
    "for signal, df in actual_report_history_df.reset_index().groupby('signal'):\n",
    "    ax.scatter(x=df['index'], y=df['report'], label=signal, marker='.', c=signal, s=3)\n",
    "ax.hlines(y=2/3, xmin=0, xmax=len(actual_report_history_df), colors='black', linestyles='dashdot')\n",
    "ax.hlines(y=1/3, xmin=0, xmax=len(actual_report_history_df) , colors='black', linestyles='dashdot')\n",
    "ax.legend()\n",
    "plt.title('Actual Report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(r_ball_pred_history_list))\n",
    "fig = plt.figure(figsize=(15, 4))\n",
    "plt.plot(r_ball_pred_history_list, 'r.', zorder=-100, label='red ball')\n",
    "plt.plot(b_ball_pred_history_list, 'b.', zorder=-99, label = 'blue ball', alpha=0.8)\n",
    "plt.hlines(y=2/3, xmin=0, xmax=len(r_ball_pred_history_list), colors='black', linestyles='dashdot')\n",
    "plt.hlines(y=1/3, xmin=0, xmax=len(b_ball_pred_history_list) , colors='black', linestyles='dashdot')\n",
    "plt.legend()\n",
    "plt.title('Report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expit(agent.report([1, 0, 0.5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expit(agent.report([0, 1, 0.5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if explorer.learning:\n",
    "    fig = plt.figure(figsize=(15, 4))\n",
    "    plt.plot(explorer_std_list)\n",
    "    plt.title('Explorer Standard Diviation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 4))\n",
    "plt.plot(r_ball_mean_history_list, 'r', label = 'red ball')\n",
    "plt.plot(b_ball_mean_history_list,label = 'blue ball')\n",
    "plt.hlines(y=np.log(2), xmin=0, xmax=len(r_ball_mean_history_list), colors='red', linestyles='dashdot')\n",
    "plt.hlines(y=np.log(1/2), xmin=0, xmax=len(b_ball_mean_history_list) , colors='blue', linestyles='dashdot')\n",
    "plt.legend()\n",
    "plt.title('Mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 4))\n",
    "plt.plot(mean_weights_history[1:, 0], 'r', label='Red weight')\n",
    "plt.plot(mean_weights_history[1:, 1], label='Blue weight')\n",
    "plt.plot(mean_weights_history[1:, 2], 'g', label='Prior weight')\n",
    "plt.hlines(y=np.log(2), xmin=0, xmax=len(mean_weights_history), colors='red', linestyles='dashdot')\n",
    "plt.hlines(y=np.log(1/2), xmin=0, xmax=len(mean_weights_history) , colors='blue', linestyles='dashdot')\n",
    "plt.hlines(y=0, xmin=0, xmax=len(mean_weights_history) , colors='green', linestyles='dashdot')\n",
    "plt.legend()\n",
    "plt.title('Weights for Mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 4))\n",
    "grad_mean_history_df.plot(ax=ax, color=['red', 'blue', 'green'])\n",
    "ax.hlines(y=0, xmin=0, xmax=len(grad_mean_history_df), linestyles='dashdot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "grad_mean_successive_dot_list = []\n",
    "for index, row in grad_mean_history_df.iterrows():\n",
    "    if i != len(grad_mean_history_df):\n",
    "        grad_mean_successive_dot_list.append(np.dot(row, grad_mean_history_df.iloc[i, :]))\n",
    "        i += 1\n",
    "grad_mean_successive_dot = np.array(grad_b_ball_adam_mean_history_list)\n",
    "grad_mean_successive_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import uniform_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_size = 1000\n",
    "fig, axs = plt.subplots(2, figsize=(15, 8))\n",
    "axs[0].plot(grad_mean_successive_dot)\n",
    "axs[0].hlines(y=0, xmin=0, xmax=len(grad_mean_successive_dot), linestyles='dashdot', color='black')\n",
    "axs[0].set_title('Successive gradients dot product')\n",
    "axs[1].plot(uniform_filter1d(grad_mean_successive_dot, size=moving_size))\n",
    "axs[1].hlines(y=0, xmin=0, xmax=len(grad_mean_successive_dot), linestyles='dashdot', color='black')\n",
    "axs[1].set_title('Successive gradients dot product size %i moving average'%moving_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, figsize=(15, 8))\n",
    "axs[0].plot(grad_r_ball_mean_history, 'r', label = 'red ball', zorder=-100)\n",
    "axs[1].plot(grad_b_ball_mean_history,label = 'blue ball', zorder=-100)\n",
    "axs[0].hlines(y=0, xmin=0, xmax=grad_r_ball_mean_history.shape[0], colors='black', linestyles='dashdot')\n",
    "axs[1].hlines(y=0, xmin=0, xmax=grad_b_ball_mean_history.shape[0], colors='black', linestyles='dashdot')\n",
    "fig.legend()\n",
    "fig.suptitle('Signal Mean Gradients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, figsize=(15, 8))\n",
    "axs[0].plot(grad_r_ball_v_mean_history, 'r', label = 'red ball', zorder=-100)\n",
    "axs[1].plot(grad_b_ball_v_mean_history,label = 'blue ball', zorder=-100)\n",
    "axs[0].hlines(y=0, xmin=0, xmax=grad_r_ball_v_mean_history.shape[0], colors='black', linestyles='dashdot')\n",
    "axs[1].hlines(y=0, xmin=0, xmax=grad_b_ball_v_mean_history.shape[0], colors='black', linestyles='dashdot')\n",
    "fig.legend()\n",
    "fig.suptitle('Signal Mean Gradients (momentum)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, figsize=(15, 8))\n",
    "axs[0].plot(grad_r_ball_adam_mean_history, 'r', label = 'red ball', zorder=-100)\n",
    "axs[1].plot(grad_b_ball_adam_mean_history,label = 'blue ball', zorder=-100)\n",
    "axs[0].hlines(y=0, xmin=0, xmax=grad_r_ball_v_mean_history.shape[0], colors='black', linestyles='dashdot')\n",
    "axs[1].hlines(y=0, xmin=0, xmax=grad_b_ball_v_mean_history.shape[0], colors='black', linestyles='dashdot')\n",
    "fig.legend()\n",
    "fig.suptitle('Signal Mean Gradients (Adam)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, figsize=(15, 8))\n",
    "# axs[0].plot(grad_r_ball_mean_history[:, 2], 'r', label = 'red ball', zorder = -100)\n",
    "# axs[1].plot(grad_b_ball_mean_history[:, 2],label = 'blue ball', zorder = -100)\n",
    "# axs[0].hlines(y=0, xmin=0, xmax=grad_r_ball_mean_history.shape[0], colors='black', linestyles='dashdot')\n",
    "# axs[1].hlines(y=0, xmin=0, xmax=grad_b_ball_mean_history.shape[0], colors='black', linestyles='dashdot')\n",
    "# fig.legend()\n",
    "# fig.suptitle('Prior Mean Gradient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(2, figsize=(15, 8))\n",
    "# axs[0].plot(grad_r_ball_v_mean_history[:, 2], 'r', label = 'red ball', zorder = -100)\n",
    "# axs[1].plot(grad_b_ball_v_mean_history[:, 2],label = 'blue ball', zorder = -100)\n",
    "# axs[0].hlines(y=0, xmin=0, xmax=grad_r_ball_v_mean_history.shape[0], colors='black', linestyles='dashdot')\n",
    "# axs[1].hlines(y=0, xmin=0, xmax=grad_b_ball_v_mean_history.shape[0], colors='black', linestyles='dashdot')\n",
    "# fig.legend()\n",
    "# fig.suptitle('Prior Mean Gradient (Momentum)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
