{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Bandits Agent with Policy Gradient Method (Stochastic) in Prediction Markets Problem\n",
    "---\n",
    "This is a program that simulates an agent who trades in a prediction market. The problem that the prediction market aims to solve is to predict the real distribution of a random variable. We define the random variable as the colour of a bucket. The problem design comes from a human-subjective experiment for decision markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from main import stochastic_training_notebook\n",
    "from Environment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent0\n",
      "learning_rate_theta= 0.0001  learning_rate_wv= 0.0001\n",
      "memory_size= 16  standard deviation= 0.3\n",
      "Updating weights with regular algorithm.\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88433c38d0954810b586025548db8a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ly/rf134w615xx1h_38hyw4ldx4gv1r4c/T/ipykernel_65505/41600645.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0msignal_size_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magent_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msignal_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m agent_list, dm_outcome_list, prior_outcome_list, nb_outcome_list, loss_list = stochastic_training_notebook(\n\u001b[0m\u001b[1;32m     30\u001b[0m                              \u001b[0magent_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_wv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                              \u001b[0mmemory_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_episodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Develop/HRI/contexutal-bandits-problem-continous-actionspace-prediction-market/main.py\u001b[0m in \u001b[0;36mstochastic_training_notebook\u001b[0;34m(agent_list, learning_rate_theta, learning_rate_wv, memory_size, batch_size, training_episodes, decay_rate, beta1, beta2, algorithm, learning_std, fixed_std, pr_red_ball_red_bucket, pr_red_ball_blue_bucket, prior_red_list, agent_num, action_num, score_func, decision_rule, preferred_colour_pr_list, evaluation_step, weights_init, report_order, signal_size_list)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreport_order\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mReportOrder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRANDOM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         dm_outcome, prior_outcome, nb_outcome, loss = stochastic_iterative_policy(action_num, prior_red_list, pr_red_ball_red_bucket,\n\u001b[0m\u001b[1;32m     39\u001b[0m                                                     \u001b[0mpr_red_ball_blue_bucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                                                     decision_rule, preferred_colour_pr_list, signal_size_list)\n",
      "\u001b[0;32m~/Develop/HRI/contexutal-bandits-problem-continous-actionspace-prediction-market/main.py\u001b[0m in \u001b[0;36mstochastic_iterative_policy\u001b[0;34m(action_num, prior_red_list, pr_red_ball_red_bucket, pr_red_ball_blue_bucket, agent_list, t, decay_rate, score_func, decision_rule, preferred_colour_pr_list, signal_size_list)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore_experience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Develop/HRI/contexutal-bandits-problem-continous-actionspace-prediction-market/PolicyGradientAgent.py\u001b[0m in \u001b[0;36mbatch_update\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mbatch_gradient_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mgradient_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_gradient_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_std\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mgradient_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_gradient_stds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Develop/HRI/contexutal-bandits-problem-continous-actionspace-prediction-market/venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3419\u001b[0;31m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0m\u001b[1;32m   3420\u001b[0m                           out=out, **kwargs)\n\u001b[1;32m   3421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Develop/HRI/contexutal-bandits-problem-continous-actionspace-prediction-market/venv/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         ret = um.true_divide(\n\u001b[0m\u001b[1;32m    181\u001b[0m                 ret, rcount, out=ret, casting='unsafe', subok=False)\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_float16_result\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "signal_size = 2\n",
    "learning_rate_theta = 1e-4\n",
    "learning_rate_wv = 1e-4\n",
    "memory_size = 16\n",
    "batch_size = 16\n",
    "training_episodes = int(3e6)\n",
    "decay_rate = 0\n",
    "beta1 = 0.9\n",
    "beta2 = 0.9999\n",
    "algorithm = Algorithm.REGULAR\n",
    "learning_std = False\n",
    "fixed_std = 0.3\n",
    "# Bucket parameters\n",
    "pr_red_ball_red_bucket = 2/3\n",
    "pr_red_ball_blue_bucket = 1/3\n",
    "prior_red_list = logit([2/3, 1/2, 1/3])\n",
    "# prior_red_list = None\n",
    "agent_num=1\n",
    "action_num=2\n",
    "preferred_colour_pr_list = [0.9, 0.1]\n",
    "score_func = ScoreFunction.LOG\n",
    "decision_rule = DecisionRule.STOCHASTIC\n",
    "agent_list = []\n",
    "evaluation_step = 1\n",
    "weights_init = WeightsInit.ZERO\n",
    "report_order = ReportOrder.FIXED\n",
    "signal_size_list = np.ones(shape=agent_num, dtype=int) * signal_size\n",
    "\n",
    "agent_list, dm_outcome_list, prior_outcome_list, nb_outcome_list, loss_list = stochastic_training_notebook(\n",
    "                             agent_list, learning_rate_theta, learning_rate_wv,\n",
    "                             memory_size, batch_size, training_episodes,\n",
    "                             decay_rate, beta1, beta2, algorithm, learning_std,\n",
    "                             fixed_std, pr_red_ball_red_bucket, pr_red_ball_blue_bucket,\n",
    "                             prior_red_list, agent_num, action_num, score_func, decision_rule, \n",
    "                             preferred_colour_pr_list, evaluation_step, weights_init, report_order, signal_size_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_size_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backwards_index = int(1e5)\n",
    "print(np.mean(prior_outcome_list[backwards_index:]))\n",
    "print(np.mean(dm_outcome_list[backwards_index:]))\n",
    "print(np.mean(nb_outcome_list[backwards_index:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(loss_list[backwards_index:]))\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for agent in agent_list:\n",
    "#     agent.reward_history_plot(top_margin=0.15, bottom_margin=0.15)\n",
    "#     agent.report_history_plot()\n",
    "    agent.mean_gradients_history_plot()\n",
    "    agent.mean_gradients_successive_dot_product_plot()\n",
    "#     agent.mean_history_plot()\n",
    "    agent.mean_weights_history_plot()\n",
    "    agent.std_gradients_history_plot()\n",
    "    agent.std_history_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = agent_list[0].theta_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = agent_list[1].theta_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'prior_outcome':prior_outcome_list, 'dm_outcome':dm_outcome_list, 'nb_outcome': nb_outcome_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = df[df['dm_outcome']!=df['nb_outcome']].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = index + int(2e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df = agent_list[1].report_history_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df.iloc[index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array([0.693, -0.693]) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(np.array([[1,0,0.5, 0, 0, 0]]), t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weights_df_list = agent_list[0].mean_weights_history_df()\n",
    "\n",
    "mean_weights_df_list[0].tail()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_weights_df_list = agent_list[1].mean_weights_history_df()\n",
    "\n",
    "mean_weights_df_list[0].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mean_weights_df_list[1].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report_history_df = agent_list[0].report_history_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_history_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_history_df = agent_list[1].report_history_dataframe()\n",
    "report_history_df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy import stats\n",
    "from scipy.special import logit, expit\n",
    "from Environment import expected_log_reward_red_ball, analytical_best_report_ru_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mu = 0\n",
    "sigma = 0.2\n",
    "prior_red = 0.5\n",
    "colours = ['red', 'blue', 'yellow', 'green', 'purple']\n",
    "variance = np.square(sigma)\n",
    "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "z = np.linspace(mu-2*sigma, mu+2*sigma, 5)\n",
    "fig, axs = plt.subplots(5, figsize=(14, 4*5))\n",
    "axs[0].plot(x, stats.norm.pdf(x, mu, sigma))\n",
    "axs[0].vlines(z, ymin=0, ymax=np.max(stats.norm.pdf(x=x, loc=mu, scale=sigma)), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(z, zip(z, [0]*5)):\n",
    "    axs[0].annotate('%.3f'%value, xy=coord)\n",
    "axs[1].plot(expit(x), stats.norm.pdf(x, mu, sigma))\n",
    "axs[1].vlines(expit(z), ymin=0, ymax=np.max(stats.norm.pdf(x, mu, sigma)), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(expit(z), zip(expit(z), [0]*5)):\n",
    "    axs[1].annotate('%.3f'%value, xy=coord)\n",
    "axs[2].plot(np.log(expit(x))-np.log(1/2), stats.norm.pdf(x, mu, sigma))\n",
    "# axs[2].plot(np.log(1/2) - np.log(expit(x)), stats.norm.pdf(x, mu, sigma))\n",
    "axs[2].vlines(np.log(expit(z))-np.log(1/2), ymin=0, ymax=np.max(stats.norm.pdf(x, mu, sigma)), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(np.log(expit(z))-np.log(1/2), zip(np.log(expit(z))-np.log(1/2), [0]*5)):\n",
    "    axs[2].annotate('%.3f'%value, xy=coord)\n",
    "axs[3].plot(expit(x) - (np.square(expit(x)) + np.square(1 - expit(x)))/2 - 0.25, stats.norm.pdf(x, mu, sigma))\n",
    "axs[3].vlines(expit(z) - (np.square(expit(z)) + np.square(1 - expit(z)))/2 - 0.25, ymin=0, ymax=np.max(stats.norm.pdf(x, mu, sigma)), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(expit(z) - (np.square(expit(z)) + np.square(1 - expit(z)))/2 - 0.25, zip(expit(z) - (np.square(expit(z)) + np.square(1 - expit(z)))/2 - 0.25, [0]*5)):\n",
    "    axs[3].annotate('%.3f'%value, xy=coord)\n",
    "actual_pr_ru_rs = analytical_best_report_ru_rs(prior_red, pr_red_ball_red_bucket, pr_red_ball_blue_bucket)\n",
    "expected_init = expected_log_reward_red_ball(actual_pr_ru_rs, 1/2, prior_red)\n",
    "expected_z = expected_log_reward_red_ball(actual_pr_ru_rs, np.array(expit(z)), prior_red)\n",
    "expected_x = expected_log_reward_red_ball(actual_pr_ru_rs, np.array(expit(x)), prior_red)\n",
    "# axs[4].plot(expected_x-expected_init, stats.norm.pdf(x, mu, sigma))\n",
    "# axs[4].vlines(expected_z-expected_init, ymin=0, ymax=np.max(stats.norm.pdf(x, mu, sigma)), linestyle='dashdot', colors=colours)\n",
    "# for value, coord in zip(expected_z-expected_init, zip(expected_z-expected_init, [0]*5)):\n",
    "#     axs[4].annotate('%.3f'%value, xy=coord)\n",
    "axs[4].plot(x, expected_x-expected_init)\n",
    "axs[4].vlines(z, ymin=np.min(expected_x-expected_init), ymax=np.max(expected_x-expected_init), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(z, zip(z, [np.min(expected_x-expected_init)]*5)):\n",
    "    axs[4].annotate('%.3f'%value, xy=coord)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Environment import expected_log_reward_red_ball, expected_log_reward_blue_ball, analytical_best_report_ru_rs, analytical_best_report_ru_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ru1 = 1/4\n",
    "pr_ru2 = 3/4\n",
    "pr_bs_ru = 1/3\n",
    "pr_bs_bu = 2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "r2 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "r1v, r2v = np.meshgrid(r1, r2)\n",
    "actual_pr_ru_bs1 = analytical_best_report_ru_bs(pr_ru=pr_ru1, pr_bs_ru=pr_bs_ru, pr_bs_bu=pr_bs_bu)\n",
    "actual_pr_ru_bs2 = analytical_best_report_ru_bs(pr_ru=pr_ru2, pr_bs_ru=pr_bs_ru, pr_bs_bu=pr_bs_bu)\n",
    "rv = r1v * (r1v > r2v) + r2v * (r1v <= r2v)\n",
    "actual_pr_ru_bsv = actual_pr_ru_bs1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "pr_ruv = pr_ru1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_pr_ru_bsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dm_expected_log_reward_blue_ball(pr_ru1, pr_ru2, pr_bs_ru, pr_bs_bu):\n",
    "    r1 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "    r2 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "    r1v, r2v = np.meshgrid(r1, r2)\n",
    "    actual_pr_ru_bs1 = analytical_best_report_ru_bs(pr_ru=pr_ru1, pr_bs_ru=pr_bs_ru, pr_bs_bu=pr_bs_bu)\n",
    "    actual_pr_ru_bs2 = analytical_best_report_ru_bs(pr_ru=pr_ru2, pr_bs_ru=pr_bs_ru, pr_bs_bu=pr_bs_bu)\n",
    "    rv = r1v * (r1v > r2v) + r2v * (r1v <= r2v)\n",
    "    actual_pr_ru_bsv = actual_pr_ru_bs1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "    pr_ruv = pr_ru1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "    return r1v, r2v, expected_log_reward_blue_ball(actual_pr_ru_bs=actual_pr_ru_bsv, estimated_pr_ru_bs=rv, pr_ru=pr_ruv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1v, r2v, z = dm_expected_log_reward_blue_ball( pr_ru1, pr_ru2, pr_bs_ru, pr_bs_bu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "# ax.contour3D(r1v, r2v, z, 100, cmap='binary')\n",
    "ax.plot_surface(r1v, r2v, z, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_xlabel('r1')\n",
    "ax.set_ylabel('r2')\n",
    "ax.set_zlabel('expectation')\n",
    "ax.view_init(90, 60)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ru1 = 1/4\n",
    "pr_ru2 = 3/4\n",
    "pr_rs_ru = 2/3\n",
    "pr_rs_bu = 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dm_expected_log_reward_red_ball(pr_ru1, pr_ru2, pr_rs_ru, pr_rs_bu):\n",
    "    r1 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "    r2 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "    r1v, r2v = np.meshgrid(r1, r2)    \n",
    "    actual_pr_ru_rs1 = analytical_best_report_ru_rs(pr_ru=pr_ru1, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu)\n",
    "    actual_pr_ru_rs2 = analytical_best_report_ru_rs(pr_ru=pr_ru2, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu)   \n",
    "    rv = r1v * (r1v > r2v) + r2v * (r1v <= r2v)\n",
    "    actual_pr_ru_rsv = actual_pr_ru_rs1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "    pr_ruv = pr_ru1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "    return r1v, r2v, expected_log_reward_red_ball(actual_pr_ru_rs=actual_pr_ru_rsv, estimated_pr_ru_rs=rv, pr_ru=pr_ruv)\n",
    "\n",
    "r1v, r2v, z = dm_expected_log_reward_red_ball(pr_ru1, pr_ru2, pr_rs_ru, pr_rs_bu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "# ax.contour3D(r1v, r2v, z, 100, cmap='binary')\n",
    "ax.plot_surface(r1v, r2v, z, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_xlabel('r1')\n",
    "ax.set_ylabel('r2')\n",
    "ax.set_zlabel('expectation')\n",
    "ax.view_init(90, 60)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Surface(z=z, x=r1v, y=r2v)])\n",
    "fig.update_layout(title='Mt Bruno Elevation', autosize=True,\n",
    "#                   width=500, height=500,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ru1 = 1/4\n",
    "pr_ru2 = 3/4\n",
    "pr_rs_ru = 2/3\n",
    "pr_rs_bu = 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import Generator, PCG64\n",
    "def stochastic_decision_rule(r1v, r2v, probabilities, pr_ru1, pr_ru2, pr_rs_ru, pr_rs_bu):\n",
    "#     generator = Generator(PCG64())\n",
    "    result_array = np.zeros(r1v.shape)\n",
    "    r_stack_v = np.dstack((r1v, r2v))\n",
    "    for i in range(r_stack_v.shape[0]):\n",
    "        for j in range(r_stack_v.shape[1]):\n",
    "            r1, r2 = r_stack_v[i][j]\n",
    "            if r1 > r2:\n",
    "                pr = probabilities\n",
    "            else:\n",
    "                pr = probabilities[::-1]\n",
    "            actual_pr_ru_rs1 = analytical_best_report_ru_rs(pr_ru=pr_ru1, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu)\n",
    "            actual_pr_ru_rs2 = analytical_best_report_ru_rs(pr_ru=pr_ru2, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu) \n",
    "            result_array[i][j] = expected_log_reward_red_ball(actual_pr_ru_rs=actual_pr_ru_rs1, estimated_pr_ru_rs=r1, pr_ru=pr_ru1)/pr[0] + expected_log_reward_red_ball(actual_pr_ru_rs=pr_ru2, estimated_pr_ru_rs=r2, pr_ru=pr_ru2)/pr[1]\n",
    "            \n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z = stochastic_decision_rule(r1v, r2v, [0.8, 0.2], pr_ru1, pr_ru2, pr_rs_ru, pr_rs_bu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_pr_ru_rs1 = analytical_best_report_ru_rs(pr_ru=pr_ru1, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu)\n",
    "actual_pr_ru_rs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Surface(z=z, x=r1v, y=r2v)])\n",
    "fig.update_layout(title='Mt Bruno Elevation', autosize=True,\n",
    "#                   width=500, height=500,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (contexutal-bandits-problem-continous-actionspace-prediction-market)",
   "language": "python",
   "name": "pycharm-edabad71"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
