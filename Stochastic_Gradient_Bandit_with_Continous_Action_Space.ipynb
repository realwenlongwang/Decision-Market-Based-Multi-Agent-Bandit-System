{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Bandits Agent with Policy Gradient Method (Stochastic) in Prediction Markets Problem\n",
    "---\n",
    "This is a program that simulates an agent who trades in a prediction market. The problem that the prediction market aims to solve is to predict the real distribution of a random variable. We define the random variable as the colour of a bucket. The problem design comes from a human-subjective experiment for decision markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from main import stochastic_training_notebook\n",
    "from Environment import *\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "import pyarrow.feather as feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent0\n",
      "learning_rate_theta= 0.0001  learning_rate_wv= 0.0001\n",
      "memory_size= 16  standard deviation= 0.3\n",
      "Updating weights with regular algorithm.\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1899cadb3647d3b2982e27db5cff36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent_num=1\n",
    "action_num=2\n",
    "signal_size =1\n",
    "learning_rate_theta = 1e-4 / signal_size\n",
    "learning_rate_wv = 1e-4 / signal_size\n",
    "memory_size = 16\n",
    "batch_size = 16\n",
    "training_episodes = int(8e6)\n",
    "decay_rate = 0\n",
    "beta1 = 0.9\n",
    "beta2 = 0.9999\n",
    "algorithm = Algorithm.REGULAR\n",
    "learning_std = False\n",
    "fixed_std = 0.3\n",
    "# Bucket parameters\n",
    "pr_red_ball_red_bucket = 2/3\n",
    "pr_red_ball_blue_bucket = 1/3\n",
    "# prior_red_list = logit([2/3, 1/2, 1/3])\n",
    "prior_red_list = None\n",
    "preferred_colour_pr_list = [0.99, 0.01]\n",
    "score_func = ScoreFunction.LOG\n",
    "decision_rule = DecisionRule.DETERMINISTIC\n",
    "agent_list = []\n",
    "evaluation_step = 1\n",
    "weights_init = WeightsInit.RANDOM\n",
    "report_order = ReportOrder.FIXED\n",
    "signal_size_list = np.ones(shape=agent_num, dtype=int) * signal_size\n",
    "\n",
    "metric_dict = stochastic_training_notebook(\n",
    "                             agent_list, learning_rate_theta, learning_rate_wv,\n",
    "                             memory_size, batch_size, training_episodes,\n",
    "                             decay_rate, beta1, beta2, algorithm, learning_std,\n",
    "                             fixed_std, pr_red_ball_red_bucket, pr_red_ball_blue_bucket,\n",
    "                             prior_red_list, agent_num, action_num, score_func, decision_rule, \n",
    "                             preferred_colour_pr_list, evaluation_step, weights_init, report_order, signal_size_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "sequence_number = 1\n",
    "parent_folder_name = 'Deterministic' # 'Deterministic' or 'Stochastic'\n",
    "\n",
    "dir_name = r'ag{}_ac{}_sig{}_lrt{}_te{}_{}_{}_{}_{}_{}_{}_{}_{}/'.format(agent_num, action_num, signal_size, learning_rate_theta, \n",
    "                                    training_episodes, algorithm.name, \n",
    "                                    'normal' if prior_red_list is None else 'list',\n",
    "                                    preferred_colour_pr_list, score_func.name,\n",
    "                                    decision_rule.name, weights_init.name, report_order.name, sequence_number)\n",
    "\n",
    "dir_path = r'./data/{}/{}'.format(parent_folder_name, dir_name)\n",
    "\n",
    "while os.path.exists(dir_path):\n",
    "    sequence_number += 1\n",
    "    dir_name = r'ag{}_ac{}_sig{}_lrt{}_te{}_{}_{}_{}_{}_{}_{}_{}_{}/'.format(agent_num, action_num, signal_size, learning_rate_theta, \n",
    "                                    training_episodes, algorithm.name, \n",
    "                                    'normal' if prior_red_list is None else 'list',\n",
    "                                    preferred_colour_pr_list, score_func.name,\n",
    "                                    decision_rule.name, weights_init.name, report_order.name, sequence_number)\n",
    "    dir_path = r'./data/{}/{}'.format(parent_folder_name, dir_name)\n",
    "    \n",
    "\n",
    "\n",
    "os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backwards_index = -int(1e6)\n",
    "print(np.mean(metric_dict['prior_outcome'][backwards_index:]))\n",
    "print(np.mean(metric_dict['dm_outcome'][backwards_index:]))\n",
    "print(np.mean(metric_dict['bayesian_outcome'][backwards_index:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loss_df = pd.DataFrame(loss_list,columns=['loss'])\n",
    "# fig, axs = plt.subplots(2, figsize=(18, 18))\n",
    "# gradients_box_plot(df=loss_df,bins=10, col_name='loss',color='red',ax=axs[0])\n",
    "# gradients_box_plot(df=loss_df.iloc[backwards_index:,:], bins=10, col_name='loss', color='blue', ax=axs[1])\n",
    "# plt.savefig(dir_path + 'loss_boxplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import uniform_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(metric_dict['loss'][backwards_index:]))\n",
    "fig, ax = plt.subplots(figsize=(15,4))\n",
    "ax.plot(metric_dict['loss'],'.',markersize=0.1, label='loss')\n",
    "average_loss = uniform_filter1d(metric_dict['loss'],size=100)\n",
    "ax.plot(average_loss,'.', markersize=0.1, label='running window average')\n",
    "lgnd = ax.legend(loc='upper right',markerscale=100)\n",
    "fig.suptitle('Root Mean Squared Log Loss')\n",
    "plt.savefig(dir_path + 'loss_dotsplot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df = pd.DataFrame(metric_dict)\n",
    "with open(dir_path + r'metric', 'wb') as f:\n",
    "    feather.write_feather(metric_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point_index = int(1e6)\n",
    "metric_df.head(check_point_index)['loss'].describe().to_csv(dir_path + 'head_loss_describe_table.csv')\n",
    "print(metric_df.head(check_point_index)['loss'].describe())\n",
    "metric_df.tail(check_point_index)['loss'].describe().to_csv(dir_path + 'tail_loss_describe_table.csv')\n",
    "print(metric_df.tail(check_point_index)['loss'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_window_size = 10000\n",
    "rolling_df = metric_df.loc[:, ['loss', 'dm_outcome', 'bayesian_outcome', 'dr_outcome']].rolling(rolling_window_size, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax1 = plt.subplots(figsize=(15,4))\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(rolling_df['loss'], label='Loss')\n",
    "ax2.plot(rolling_df['dm_outcome'],'g', label='Decision Markets outcome')\n",
    "ax2.plot(rolling_df['bayesian_outcome'], 'r', label='Bayesian outcome')\n",
    "# ax2.plot(rolling_df['dr_outcome'], 'b.',markersize=0.01)\n",
    "ax2.set_ylim([0.5,0.75])\n",
    "ax1.legend(loc='lower left', bbox_to_anchor=(0,1))\n",
    "ax2.legend(loc='lower right', bbox_to_anchor=(1,1))\n",
    "fig.suptitle('Rolling Window Metrics with Window Size ' + str(rolling_window_size), y=1.3)\n",
    "plt.savefig(dir_path + 'loss_reward_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for agent in agent_list:\n",
    "#     agent.reward_history_plot(top_margin=0.15, bottom_margin=0.15)\n",
    "#     agent.report_history_plot()\n",
    "#     agent.mean_gradients_history_plot()\n",
    "#     agent.mean_gradients_successive_dot_product_plot()\n",
    "#     agent.mean_history_plot()\n",
    "#     agent.mean_weights_history_plot()\n",
    "#     agent.std_gradients_history_plot()\n",
    "#     agent.std_history_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_num = 3\n",
    "\n",
    "fig, axs=plt.subplots(agent_num, action_num, figsize=(agent_num * 15, 5), sharex=True, sharey=True, squeeze=False)\n",
    "\n",
    "\n",
    "for agent, ag_no in zip(agent_list, range(agent_num)):\n",
    "    mean_weights_df_list = agent.mean_weights_history_df() \n",
    "    reward_df = agent.reward_history_dataframe()\n",
    "    with open(dir_path + f'{agent.name}_score', 'wb') as f:\n",
    "        feather.write_feather(reward_df, f)\n",
    "    # Save the weights\n",
    "    for no in range(2):\n",
    "        with open(dir_path + f'{agent.name}_bucket{no}_weights', 'wb') as f:\n",
    "            feather.write_feather(mean_weights_df_list[no], f)\n",
    "    \n",
    "    for df, ac_no in zip(mean_weights_df_list, range(2)):\n",
    "\n",
    "        axs[ag_no, ac_no].plot(df.iloc[1:, 0 * feature_num + 0],\n",
    "                               label='Bucket0 Red weight', color='red')\n",
    "        axs[ag_no, ac_no].plot(df.iloc[1:, 0 * feature_num + 1],\n",
    "                               label='Bucket0 Blue weight', color='blue')\n",
    "        axs[ag_no, ac_no].plot(df.iloc[1:, 0 * feature_num + 2],\n",
    "                               label='Bucket0 Prior weight', color='green')\n",
    "\n",
    "        axs[ag_no, ac_no].plot(df.iloc[1:, 1 * feature_num + 0],\n",
    "                               label='Bucket1 Red weight', color='darkred')\n",
    "        axs[ag_no, ac_no].plot(df.iloc[1:, 1 * feature_num + 1],\n",
    "                               label='Bucket1 Blue weight', color='darkblue')\n",
    "        axs[ag_no, ac_no].plot(df.iloc[1:, 1 * feature_num + 2],\n",
    "                               label='Bucket1 Prior weight', color='darkgreen')\n",
    "                \n",
    "for r_no in range(agent_num):\n",
    "    for c_no in range(action_num):\n",
    "        if r_no == 0:\n",
    "            axs[r_no, c_no].set_title(f'bucket{c_no}')\n",
    "        axs[r_no, c_no].hlines(y=np.log(pr_red_ball_red_bucket / pr_red_ball_blue_bucket), xmin=0,\n",
    "\n",
    "                            xmax=len(df), colors='red',\n",
    "                                     linestyles='dashdot')\n",
    "        axs[r_no, c_no].hlines(\n",
    "                y=np.log((1 - pr_red_ball_red_bucket) / (1 - pr_red_ball_blue_bucket)), xmin=0,\n",
    "                xmax=len(df), colors='blue',\n",
    "                linestyles='dashdot')\n",
    "        axs[r_no, c_no].hlines(y=1, xmin=0, xmax=len(df), colors='green', linestyles='dashdot')\n",
    "        axs[r_no, c_no].hlines(y=0, xmin=0, xmax=len(df), colors='black', linestyles='dashdot')\n",
    "\n",
    "handles, labels = axs[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper left', bbox_to_anchor=(0.95, 0.95), ncol=1)\n",
    "# fig.text(0.25, 1, 'Bucket 0', ha='center', va='center', fontsize=20)\n",
    "# fig.text(0.75, 1, 'Bucket 1', ha='center', va='center', fontsize=20)\n",
    "plt.savefig(dir_path + 'mean_weights.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_num=3\n",
    "for agent in agent_list:\n",
    "#     mean_weights_df_list = agent.mean_weights_history_df() \n",
    "    for df, title_no in zip(mean_weights_df_list, range(action_num)):\n",
    "    #     df = _df.rolling(100).mean()\n",
    "        last_third_idx = len(df) // 3\n",
    "        fig, ax = plt.subplots(figsize=(18, 9))\n",
    "\n",
    "        for bucket_no in range(action_num):\n",
    "            ax.plot(df.iloc[1:, bucket_no * feature_num + 0],\n",
    "                                   label='Bucket ' + str(bucket_no) + ' Red weight')\n",
    "            ax.plot(df.iloc[1:, bucket_no * feature_num + 1],\n",
    "                                   label='Bucket ' + str(bucket_no) + ' Blue weight')\n",
    "            ax.plot(df.iloc[1:, bucket_no * feature_num + 2],\n",
    "                                   label='Bucket ' + str(bucket_no) + ' Prior weight')\n",
    "\n",
    "        ax.hlines(y=np.log(pr_red_ball_red_bucket / pr_red_ball_blue_bucket), xmin=0,\n",
    "\n",
    "                        xmax=len(df), colors='red',\n",
    "                                 linestyles='dashdot')\n",
    "        ax.annotate('%.3f' % np.log(pr_red_ball_red_bucket / pr_red_ball_blue_bucket),\n",
    "                                   xy=(len(df) / 2,\n",
    "                                       np.log(pr_red_ball_red_bucket / pr_red_ball_blue_bucket)),\n",
    "                                   xytext=(len(df) / 2, np.log(2) / 2), arrowprops=dict(arrowstyle=\"->\"))\n",
    "        if bucket_no == title_no:\n",
    "            ax.annotate('std:%.3f' % df.iloc[last_third_idx:, 0].std(),\n",
    "                                   xy=(len(df) * 0.8,\n",
    "                                       np.log(pr_red_ball_red_bucket / pr_red_ball_blue_bucket)),\n",
    "                                   xytext=(len(df) * 0.8, np.log(2) / 2), arrowprops=dict(arrowstyle=\"->\"))\n",
    "        ax.hlines(\n",
    "            y=np.log((1 - pr_red_ball_red_bucket) / (1 - pr_red_ball_blue_bucket)), xmin=0,\n",
    "            xmax=len(df), colors='blue',\n",
    "            linestyles='dashdot')\n",
    "        ax.annotate(\n",
    "            '%.3f' % np.log((1 - pr_red_ball_red_bucket) / (1 - pr_red_ball_blue_bucket)),\n",
    "            xy=(len(df) / 2, np.log((1 - pr_red_ball_red_bucket) / (1 - pr_red_ball_blue_bucket))),\n",
    "            xytext=(len(df) / 2, np.log(1 / 2) / 2), arrowprops=dict(arrowstyle=\"->\"))\n",
    "        if bucket_no == title_no:\n",
    "            ax.annotate(\n",
    "            'std:%.3f' % df.iloc[last_third_idx:, 1].std(),\n",
    "            xy=(len(df) * 0.8, np.log((1 - pr_red_ball_red_bucket) / (1 - pr_red_ball_blue_bucket))),\n",
    "            xytext=(len(df) * 0.8, np.log(1 / 2) / 2), arrowprops=dict(arrowstyle=\"->\"))\n",
    "        ax.hlines(y=1, xmin=0, xmax=len(df), colors='green', linestyles='dashdot')\n",
    "        ax.hlines(y=0, xmin=0, xmax=len(df), colors='black', linestyles='dashdot')\n",
    "        ax.legend(loc='lower left', bbox_to_anchor=(0,1), ncol=action_num)\n",
    "        ax.set_title('Bucket ' + str(title_no) + ' Mean Weights History', y=1.3)\n",
    "        plt.savefig(dir_path + agent.name + '_bucket' + str(title_no) + '_mean_weights.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from scipy import stats\n",
    "from scipy.special import logit, expit\n",
    "from Environment import expected_log_reward_red_ball, analytical_best_report_ru_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mu = 0\n",
    "sigma = 0.2\n",
    "prior_red = 0.5\n",
    "colours = ['red', 'blue', 'yellow', 'green', 'purple']\n",
    "variance = np.square(sigma)\n",
    "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
    "z = np.linspace(mu-2*sigma, mu+2*sigma, 5)\n",
    "fig, axs = plt.subplots(5, figsize=(14, 4*5))\n",
    "axs[0].plot(x, stats.norm.pdf(x, mu, sigma))\n",
    "axs[0].vlines(z, ymin=0, ymax=np.max(stats.norm.pdf(x=x, loc=mu, scale=sigma)), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(z, zip(z, [0]*5)):\n",
    "    axs[0].annotate('%.3f'%value, xy=coord)\n",
    "axs[1].plot(expit(x), stats.norm.pdf(x, mu, sigma))\n",
    "axs[1].vlines(expit(z), ymin=0, ymax=np.max(stats.norm.pdf(x, mu, sigma)), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(expit(z), zip(expit(z), [0]*5)):\n",
    "    axs[1].annotate('%.3f'%value, xy=coord)\n",
    "axs[2].plot(np.log(expit(x))-np.log(1/2), stats.norm.pdf(x, mu, sigma))\n",
    "# axs[2].plot(np.log(1/2) - np.log(expit(x)), stats.norm.pdf(x, mu, sigma))\n",
    "axs[2].vlines(np.log(expit(z))-np.log(1/2), ymin=0, ymax=np.max(stats.norm.pdf(x, mu, sigma)), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(np.log(expit(z))-np.log(1/2), zip(np.log(expit(z))-np.log(1/2), [0]*5)):\n",
    "    axs[2].annotate('%.3f'%value, xy=coord)\n",
    "axs[3].plot(expit(x) - (np.square(expit(x)) + np.square(1 - expit(x)))/2 - 0.25, stats.norm.pdf(x, mu, sigma))\n",
    "axs[3].vlines(expit(z) - (np.square(expit(z)) + np.square(1 - expit(z)))/2 - 0.25, ymin=0, ymax=np.max(stats.norm.pdf(x, mu, sigma)), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(expit(z) - (np.square(expit(z)) + np.square(1 - expit(z)))/2 - 0.25, zip(expit(z) - (np.square(expit(z)) + np.square(1 - expit(z)))/2 - 0.25, [0]*5)):\n",
    "    axs[3].annotate('%.3f'%value, xy=coord)\n",
    "actual_pr_ru_rs = analytical_best_report_ru_rs(prior_red, pr_red_ball_red_bucket, pr_red_ball_blue_bucket)\n",
    "expected_init = expected_log_reward_red_ball(actual_pr_ru_rs, 1/2, prior_red)\n",
    "expected_z = expected_log_reward_red_ball(actual_pr_ru_rs, np.array(expit(z)), prior_red)\n",
    "expected_x = expected_log_reward_red_ball(actual_pr_ru_rs, np.array(expit(x)), prior_red)\n",
    "# axs[4].plot(expected_x-expected_init, stats.norm.pdf(x, mu, sigma))\n",
    "# axs[4].vlines(expected_z-expected_init, ymin=0, ymax=np.max(stats.norm.pdf(x, mu, sigma)), linestyle='dashdot', colors=colours)\n",
    "# for value, coord in zip(expected_z-expected_init, zip(expected_z-expected_init, [0]*5)):\n",
    "#     axs[4].annotate('%.3f'%value, xy=coord)\n",
    "axs[4].plot(x, expected_x-expected_init)\n",
    "axs[4].vlines(z, ymin=np.min(expected_x-expected_init), ymax=np.max(expected_x-expected_init), linestyle='dashdot', colors=colours)\n",
    "for value, coord in zip(z, zip(z, [np.min(expected_x-expected_init)]*5)):\n",
    "    axs[4].annotate('%.3f'%value, xy=coord)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Environment import expected_log_reward_red_ball, expected_log_reward_blue_ball, analytical_best_report_ru_rs, analytical_best_report_ru_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ru1 = 1/4\n",
    "pr_ru2 = 3/4\n",
    "pr_bs_ru = 1/3\n",
    "pr_bs_bu = 2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "r2 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "r1v, r2v = np.meshgrid(r1, r2)\n",
    "actual_pr_ru_bs1 = analytical_best_report_ru_bs(pr_ru=pr_ru1, pr_bs_ru=pr_bs_ru, pr_bs_bu=pr_bs_bu)\n",
    "actual_pr_ru_bs2 = analytical_best_report_ru_bs(pr_ru=pr_ru2, pr_bs_ru=pr_bs_ru, pr_bs_bu=pr_bs_bu)\n",
    "rv = r1v * (r1v > r2v) + r2v * (r1v <= r2v)\n",
    "actual_pr_ru_bsv = actual_pr_ru_bs1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "pr_ruv = pr_ru1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_pr_ru_bsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dm_expected_log_reward_blue_ball(pr_ru1, pr_ru2, pr_bs_ru, pr_bs_bu):\n",
    "    r1 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "    r2 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "    r1v, r2v = np.meshgrid(r1, r2)\n",
    "    actual_pr_ru_bs1 = analytical_best_report_ru_bs(pr_ru=pr_ru1, pr_bs_ru=pr_bs_ru, pr_bs_bu=pr_bs_bu)\n",
    "    actual_pr_ru_bs2 = analytical_best_report_ru_bs(pr_ru=pr_ru2, pr_bs_ru=pr_bs_ru, pr_bs_bu=pr_bs_bu)\n",
    "    rv = r1v * (r1v > r2v) + r2v * (r1v <= r2v)\n",
    "    actual_pr_ru_bsv = actual_pr_ru_bs1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "    pr_ruv = pr_ru1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "    return r1v, r2v, expected_log_reward_blue_ball(actual_pr_ru_bs=actual_pr_ru_bsv, estimated_pr_ru_bs=rv, pr_ru=pr_ruv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1v, r2v, z = dm_expected_log_reward_blue_ball( pr_ru1, pr_ru2, pr_bs_ru, pr_bs_bu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "# ax.contour3D(r1v, r2v, z, 100, cmap='binary')\n",
    "ax.plot_surface(r1v, r2v, z, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_xlabel('r1')\n",
    "ax.set_ylabel('r2')\n",
    "ax.set_zlabel('expectation')\n",
    "ax.view_init(90, 60)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ru1 = 1/4\n",
    "pr_ru2 = 3/4\n",
    "pr_rs_ru = 2/3\n",
    "pr_rs_bu = 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dm_expected_log_reward_red_ball(pr_ru1, pr_ru2, pr_rs_ru, pr_rs_bu):\n",
    "    r1 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "    r2 = np.linspace(start=0.01, stop=0.99, num=50)\n",
    "    r1v, r2v = np.meshgrid(r1, r2)    \n",
    "    actual_pr_ru_rs1 = analytical_best_report_ru_rs(pr_ru=pr_ru1, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu)\n",
    "    actual_pr_ru_rs2 = analytical_best_report_ru_rs(pr_ru=pr_ru2, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu)   \n",
    "    rv = r1v * (r1v > r2v) + r2v * (r1v <= r2v)\n",
    "    actual_pr_ru_rsv = actual_pr_ru_rs1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "    pr_ruv = pr_ru1 * (r1v > r2v) + pr_ru2 * (r1v <= r2v)\n",
    "    return r1v, r2v, expected_log_reward_red_ball(actual_pr_ru_rs=actual_pr_ru_rsv, estimated_pr_ru_rs=rv, pr_ru=pr_ruv)\n",
    "\n",
    "r1v, r2v, z = dm_expected_log_reward_red_ball(pr_ru1, pr_ru2, pr_rs_ru, pr_rs_bu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "# ax.contour3D(r1v, r2v, z, 100, cmap='binary')\n",
    "ax.plot_surface(r1v, r2v, z, rstride=1, cstride=1,\n",
    "                cmap='viridis', edgecolor='none')\n",
    "ax.set_xlabel('r1')\n",
    "ax.set_ylabel('r2')\n",
    "ax.set_zlabel('expectation')\n",
    "ax.view_init(90, 60)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Surface(z=z, x=r1v, y=r2v)])\n",
    "fig.update_layout(title='Mt Bruno Elevation', autosize=True,\n",
    "#                   width=500, height=500,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_ru1 = 1/4\n",
    "pr_ru2 = 3/4\n",
    "pr_rs_ru = 2/3\n",
    "pr_rs_bu = 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import Generator, PCG64\n",
    "def stochastic_decision_rule(r1v, r2v, probabilities, pr_ru1, pr_ru2, pr_rs_ru, pr_rs_bu):\n",
    "#     generator = Generator(PCG64())\n",
    "    result_array = np.zeros(r1v.shape)\n",
    "    r_stack_v = np.dstack((r1v, r2v))\n",
    "    for i in range(r_stack_v.shape[0]):\n",
    "        for j in range(r_stack_v.shape[1]):\n",
    "            r1, r2 = r_stack_v[i][j]\n",
    "            if r1 > r2:\n",
    "                pr = probabilities\n",
    "            else:\n",
    "                pr = probabilities[::-1]\n",
    "            actual_pr_ru_rs1 = analytical_best_report_ru_rs(pr_ru=pr_ru1, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu)\n",
    "            actual_pr_ru_rs2 = analytical_best_report_ru_rs(pr_ru=pr_ru2, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu) \n",
    "            result_array[i][j] = expected_log_reward_red_ball(actual_pr_ru_rs=actual_pr_ru_rs1, estimated_pr_ru_rs=r1, pr_ru=pr_ru1)/pr[0] + expected_log_reward_red_ball(actual_pr_ru_rs=pr_ru2, estimated_pr_ru_rs=r2, pr_ru=pr_ru2)/pr[1]\n",
    "            \n",
    "    return result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z = stochastic_decision_rule(r1v, r2v, [0.8, 0.2], pr_ru1, pr_ru2, pr_rs_ru, pr_rs_bu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_pr_ru_rs1 = analytical_best_report_ru_rs(pr_ru=pr_ru1, pr_rs_ru=pr_rs_ru, pr_rs_bu=pr_rs_bu)\n",
    "actual_pr_ru_rs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Surface(z=z, x=r1v, y=r2v)])\n",
    "fig.update_layout(title='Mt Bruno Elevation', autosize=True,\n",
    "#                   width=500, height=500,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (contexutal-bandits-problem-continous-actionspace-prediction-market)",
   "language": "python",
   "name": "pycharm-edabad71"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
